{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file JS01052.mat: time data '/' does not match format '%d/%m/%Y'\n",
      "Error loading file JS23074.mat: list index out of range\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_label(header):\n",
    "    snomed_code_map = {\n",
    "        '426177001': 'SB',\n",
    "        '426783006': 'SR',\n",
    "        '164889003': 'AFIB',\n",
    "        '427084000': 'ST',\n",
    "        '164890007': 'AF',\n",
    "        '427393009': 'SA',\n",
    "        '426761007': 'SVT',\n",
    "        '713422000': 'AT',\n",
    "        '233896004': 'AVNRT',\n",
    "        '233897008': 'AVRT'\n",
    "    }\n",
    "    \n",
    "    for line in header:\n",
    "        if line.startswith('#Dx:'):\n",
    "            codes = line.strip().split(':')[1].strip().split(',')\n",
    "            for code in codes:\n",
    "                if code in snomed_code_map:\n",
    "                    return snomed_code_map[code]\n",
    "    return \"Unknown\"\n",
    "def load_ecg_sample_by_filename(data_dir, file_name):\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "    #print(f\"Checking file: {file_path}.mat\")  # Add this line for debugging\n",
    "\n",
    "    if not os.path.exists(file_path + '.mat'):\n",
    "        raise ValueError(f\"No data found for the specified filename: {file_name}\")\n",
    "\n",
    "\n",
    "    # Read ECG signal from the .mat file\n",
    "    record = wfdb.rdrecord(file_path)\n",
    "    signal = record.p_signal[:, 0]\n",
    "\n",
    "    # Read the header file\n",
    "    header_content = read_header_file(file_path + '.hea')\n",
    "\n",
    "    # Extract label from the header file\n",
    "    label = extract_label(header_content)\n",
    "\n",
    "    return signal, label\n",
    "\n",
    "def read_header_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.readlines()\n",
    "    return content\n",
    "\n",
    "def load_ecg_data(data_dir, rhythm_types=None):\n",
    "    signals = []\n",
    "    labels = []\n",
    "\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.mat'):\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                try:\n",
    "                    signal, label = load_ecg_sample_by_filename(root, file_name)\n",
    "                    if rhythm_types is None or label in rhythm_types:\n",
    "                        signals.append(signal)\n",
    "                        labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading file {file}: {e}\")\n",
    "\n",
    "    return signals, labels\n",
    "\n",
    "data_dir = '/Users/aman/Downloads/ecg/WFDBRecords/'\n",
    "rhythm_types = ['SB', 'SR', 'AFIB', 'ST', 'AF', 'SA', 'SVT', 'AT', 'AVNRT', 'AVRT']\n",
    "\n",
    "signals, labels = load_ecg_data(data_dir, rhythm_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "\n",
    "def preprocess_ecg_signal(ecg_signal, lowcut=0.5, highcut=50.0, fs=500.0):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = signal.butter(1, [low, high], btype='band')\n",
    "    filtered_signal = signal.lfilter(b, a, ecg_signal)\n",
    "    normalized_signal = (filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal)\n",
    "    return normalized_signal\n",
    "\n",
    "preprocessed_signals = [preprocess_ecg_signal(signal) for signal in signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Patches\n",
    "def segment_and_save(preprocessed_signals, labels, patch_size=250):\n",
    "    segmented_signals = []\n",
    "    segmented_labels = []\n",
    "\n",
    "    for signal, label in zip(preprocessed_signals, labels):\n",
    "        patches = [signal[i:i+patch_size] for i in range(0, len(signal), patch_size)]\n",
    "        patches = [patch for patch in patches if len(patch) == patch_size]\n",
    "        segmented_signals.extend(patches)\n",
    "        segmented_labels.extend([label] * len(patches))\n",
    "\n",
    "    segmented_signals = np.array(segmented_signals)\n",
    "    segmented_labels = np.array(segmented_labels)\n",
    "\n",
    "    np.save('segmented_signals.npy', segmented_signals)\n",
    "    np.save('segmented_labels.npy', segmented_labels)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Initialize label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform labels into numbers\n",
    "labels_encoded = le.fit_transform(labels)\n",
    "\n",
    "# Assume 'preprocessed_signals' and 'labels' are your preprocessed signals and labels\n",
    "preprocessed_signals = preprocessed_signals\n",
    "labels = labels_encoded\n",
    "\n",
    "# Call the function\n",
    "segment_and_save(preprocessed_signals, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_save(input_file='segmented_signals.npy', output_file='masked_signals.npy', patch_size=250, mask_fraction=0.30):\n",
    "    # Load the segmented signals\n",
    "    data = np.load(input_file)\n",
    "\n",
    "    # Create a copy of the data to avoid modifying the original data\n",
    "    data_masked = data.copy()\n",
    "\n",
    "    # Calculate the number of patches in each ECG segment\n",
    "    num_patches = data.shape[1] // patch_size\n",
    "\n",
    "    # Calculate the number of patches to mask in each ECG segment\n",
    "    num_mask = int(mask_fraction * num_patches)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        # Choose random patches to mask\n",
    "        mask_patches = np.random.choice(num_patches, num_mask, replace=False)\n",
    "\n",
    "        for p in mask_patches:\n",
    "            # Mask the data in these patches\n",
    "            start_idx = p * patch_size\n",
    "            end_idx = start_idx + patch_size\n",
    "            data_masked[i, start_idx:end_idx] = 0\n",
    "\n",
    "    # Save the masked signals to disk\n",
    "    np.save(output_file, data_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have segmented signals saved in 'segmented_signals.npy'\n",
    "mask_and_save('segmented_signals.npy', 'masked_signals.npy', patch_size=250, mask_fraction=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, masked_signals, original_signals):\n",
    "        self.masked_signals = masked_signals\n",
    "        self.original_signals = original_signals\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.masked_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.masked_signals[idx], self.original_signals[idx]\n",
    "\n",
    "# Load the data\n",
    "masked_signals = np.load('masked_signals.npy')\n",
    "original_signals = np.load('segmented_signals.npy')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "masked_train, masked_val, original_train, original_val = train_test_split(masked_signals, original_signals, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ECGDataset(masked_train, original_train)\n",
    "val_dataset = ECGDataset(masked_val, original_val)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "class SingleLeadECGModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SingleLeadECGModel, self).__init__()\n",
    "\n",
    "        self.class_token = nn.Parameter(torch.zeros(1, 1, 128))\n",
    "\n",
    "        # Patch Embedding Module for Encoder\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=15, stride=1)\n",
    "        init.xavier_uniform_(self.conv1.weight)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=7, stride=1)\n",
    "        init.xavier_uniform_(self.conv2.weight)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=60, stride=125, dilation=2)\n",
    "        init.xavier_uniform_(self.conv3.weight)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(128)\n",
    "\n",
    "        # Transformer Blocks for Encoder\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=128, nhead=8, dim_feedforward=128*3)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=6)\n",
    "\n",
    "        # Patch Embedding Module for Decoder\n",
    "        self.decoder_linear = nn.Linear(128, 64)\n",
    "        init.xavier_uniform_(self.decoder_linear.weight)\n",
    "\n",
    "        # Transformer Blocks for Decoder\n",
    "        decoder_layers = TransformerEncoderLayer(d_model=64, nhead=8, dim_feedforward=64*3)\n",
    "        self.transformer_decoder = TransformerEncoder(decoder_layers, num_layers=3)\n",
    "\n",
    "        # Prediction Layer\n",
    "        self.pred_linear = nn.Linear(64, 250)\n",
    "        init.xavier_uniform_(self.pred_linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Patch Embedding Module for Encoder\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.ln(self.conv3(x).squeeze(-1))\n",
    "\n",
    "        # Adding class token to patches\n",
    "        class_token = self.class_token.repeat(x.size(0), 1, 1)\n",
    "        x=x.unsqueeze(1)\n",
    "        x = x + class_token\n",
    "\n",
    "        # Transformer Blocks for Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Patch Embedding Module for Decoder\n",
    "        x = self.decoder_linear(x)\n",
    "\n",
    "        # Transformer Blocks for Decoder\n",
    "        x = self.transformer_decoder(x)\n",
    "\n",
    "        # Prediction Layer\n",
    "        x = self.pred_linear(x)\n",
    "\n",
    "        # Reshaping output to match original input\n",
    "        x = x.view(-1, 1, 250)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import L1Loss\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = SingleLeadECGModel().float()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=0.05)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.5740189938924198\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 15], expected input[1, 32, 250] to have 1 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m inputs, labels \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), data[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     40\u001b[0m \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/Downloads/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m, in \u001b[0;36mSingleLeadECGModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     46\u001b[0m     \u001b[39m# Patch Embedding Module for Encoder\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     48\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m     49\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/Downloads/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Downloads/.conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Downloads/.conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 15], expected input[1, 32, 250] to have 1 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "# Training loop with validation\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].unsqueeze(1).float().to(device), data[1].unsqueeze(1).float().to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss per epoch\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {train_loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            # Get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss per epoch\n",
    "        val_loss = running_loss / len(val_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss}\")\n",
    "\n",
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
